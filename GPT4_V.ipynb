{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM13hE4oLIkqe0/nUU2gsov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ece4ebfb950b4c5399c1be758c440e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e4f6fc3885641fd8e09b7b4a9239757",
              "IPY_MODEL_3b568797a76d44078392242ee66a72f6",
              "IPY_MODEL_9374773cdb324fc28f8ff436f7635094",
              "IPY_MODEL_94e4ce8ec09f44d49448cf777f0c70c2"
            ],
            "layout": "IPY_MODEL_d9cfc4c501ea4cb8906f4ed5db300fcc"
          }
        },
        "301986b8a8d3497880a293209ce386a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5f8636eb7d47b9ab7d6f80da660277",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9ce87467534dc0839f2082ad5b356f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "8d8ebc448b2d46b99d3d75f148c1dcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6ba00734c554488a8819048035b6e51f",
            "placeholder": "​",
            "style": "IPY_MODEL_137989ec65c049ccab6ef1c8f965c94d",
            "value": ""
          }
        },
        "1384ad1874634e52bf4a0beeac19099a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ca094f54a4d54679b77ec89b468d910e",
            "style": "IPY_MODEL_d64ae1ad6f154667bb0ea5b7c3610a49",
            "value": true
          }
        },
        "7eb0de793db84b4eb6750b8aa786a099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dbdc7cff8135429daedc1c1e2136cda9",
            "style": "IPY_MODEL_2ab11f8a47ee4614a57f98b585c53c4d",
            "tooltip": ""
          }
        },
        "f38a888b2de54478894ebf1582650e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5400a3fe115a4cf086d215f31fa884c9",
            "placeholder": "​",
            "style": "IPY_MODEL_f2885ca831174312a1e0966d6ed7e3ff",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d9cfc4c501ea4cb8906f4ed5db300fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3a5f8636eb7d47b9ab7d6f80da660277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9ce87467534dc0839f2082ad5b356f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba00734c554488a8819048035b6e51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137989ec65c049ccab6ef1c8f965c94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca094f54a4d54679b77ec89b468d910e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64ae1ad6f154667bb0ea5b7c3610a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbdc7cff8135429daedc1c1e2136cda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab11f8a47ee4614a57f98b585c53c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5400a3fe115a4cf086d215f31fa884c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2885ca831174312a1e0966d6ed7e3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24f515d4ba3849bd83f913424df5600c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624ca89c6a36405d96566e8ce28a4234",
            "placeholder": "​",
            "style": "IPY_MODEL_f0421312aea84425b0cb75fbcc52a9e2",
            "value": "Connecting..."
          }
        },
        "624ca89c6a36405d96566e8ce28a4234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0421312aea84425b0cb75fbcc52a9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4f6fc3885641fd8e09b7b4a9239757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4accd481823248cea883ba78ccdefb12",
            "placeholder": "​",
            "style": "IPY_MODEL_dda192d88dc2468b917bc39fece7671e",
            "value": "Token is valid (permission: fineGrained)."
          }
        },
        "3b568797a76d44078392242ee66a72f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_021bcc6516184cc68a666e8c17add9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_5761d4862c4a417583c998cf1e33aa66",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "9374773cdb324fc28f8ff436f7635094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f2971d42cc545afb49395c78a13fb7c",
            "placeholder": "​",
            "style": "IPY_MODEL_9240e8a5579440fdb25b01990920ebf3",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "94e4ce8ec09f44d49448cf777f0c70c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5e0633db1b465597f0fe86e1aaf291",
            "placeholder": "​",
            "style": "IPY_MODEL_d30aad35b89b456aadd3d4065cc52be8",
            "value": "Login successful"
          }
        },
        "4accd481823248cea883ba78ccdefb12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda192d88dc2468b917bc39fece7671e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "021bcc6516184cc68a666e8c17add9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5761d4862c4a417583c998cf1e33aa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f2971d42cc545afb49395c78a13fb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9240e8a5579440fdb25b01990920ebf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5e0633db1b465597f0fe86e1aaf291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30aad35b89b456aadd3d4065cc52be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kendrickkkk/Basic-OOP/blob/main/GPT4_V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsntL7EZgD7i",
        "outputId": "2954690d-9515-4f1e-cc22-77f52e9bc10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiniGPT-4'...\n",
            "remote: Enumerating objects: 1833, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 1833 (delta 3), reused 3 (delta 3), pack-reused 1814 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1833/1833), 65.24 MiB | 28.63 MiB/s, done.\n",
            "Resolving deltas: 100% (1041/1041), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ThuanNaN/MiniGPT-4.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MiniGPT-4"
      ],
      "metadata": {
        "id": "9fDGf4VhgHJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cd95c3-cd5e-4d45-8bc5-9bf45af04bbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sGdw284FlZT3",
        "outputId": "6691fa93-dafd-4b9c-c822-19cf0a111b77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Collecting huggingface-hub==0.18.0 (from -r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting matplotlib==3.7.0 (from -r requirements.txt (line 5))\n",
            "  Downloading matplotlib-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting psutil==5.9.4 (from -r requirements.txt (line 6))\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting iopath (from -r requirements.txt (line 7))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml==6.0 (from -r requirements.txt (line 8))\n",
            "  Downloading PyYAML-6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex==2022.10.31 (from -r requirements.txt (line 9))\n",
            "  Downloading regex-2022.10.31-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.13.2 (from -r requirements.txt (line 10))\n",
            "  Downloading tokenizers-0.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tqdm==4.64.1 (from -r requirements.txt (line 11))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.30.0 (from -r requirements.txt (line 12))\n",
            "  Downloading transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.6.13 (from -r requirements.txt (line 13))\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting webdataset==0.2.48 (from -r requirements.txt (line 14))\n",
            "  Downloading webdataset-0.2.48-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.3.0)\n",
            "Collecting opencv-python==4.7.0.72 (from -r requirements.txt (line 16))\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting decord==0.6.0 (from -r requirements.txt (line 17))\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Collecting peft==0.4.0 (from -r requirements.txt (line 18))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (4.1.0)\n",
            "Collecting gradio==3.47.1 (from -r requirements.txt (line 20))\n",
            "  Downloading gradio-3.47.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting accelerate==0.21.0 (from -r requirements.txt (line 21))\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting bitsandbytes==0.40.2 (from -r requirements.txt (line 22))\n",
            "  Downloading bitsandbytes-0.40.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (2.0.10)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.25.2)\n",
            "Collecting visual-genome (from -r requirements.txt (line 26))\n",
            "  Downloading visual_genome-1.1.1-py2.py3-none-any.whl.metadata (840 bytes)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.20.1)\n",
            "Collecting torchmetrics[detection] (from -r requirements.txt (line 24))\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->-r requirements.txt (line 1)) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.18.0->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.18.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.18.0->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0->-r requirements.txt (line 12)) (0.5.3)\n",
            "Collecting braceexpand (from webdataset==0.2.48->-r requirements.txt (line 14))\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->-r requirements.txt (line 15)) (4.9.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.47.1->-r requirements.txt (line 20))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.6.0)\n",
            "Collecting gradio-client==0.6.0 (from gradio==3.47.1->-r requirements.txt (line 20))\n",
            "  Downloading gradio_client-0.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (6.5.2)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.47.1->-r requirements.txt (line 20))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting numpy>=1.20 (from matplotlib==3.7.0->-r requirements.txt (line 5))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (2.2.2)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.7.0->-r requirements.txt (line 5))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.0.20)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.47.1->-r requirements.txt (line 20)) (0.34.3)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.47.1->-r requirements.txt (line 20))\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1)) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio (from -r requirements.txt (line 2))\n",
            "  Downloading torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchaudio-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
            "  Downloading torchaudio-2.0.2-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "  Downloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r requirements.txt (line 3))\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting portalocker (from iopath->-r requirements.txt (line 7))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sentence-transformers (from -r requirements.txt (line 19))\n",
            "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence_transformers-2.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 19)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 19)) (1.15.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 19)) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 19)) (0.2.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics[detection]->-r requirements.txt (line 24))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 25)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 25)) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 25)) (0.4)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.11/dist-packages (from visual-genome->-r requirements.txt (line 26)) (4.5.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (5.29.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 27)) (1.3.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (1.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 27)) (4.0.12)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.47.1->-r requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.47.1->-r requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.47.1->-r requirements.txt (line 20)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.47.1->-r requirements.txt (line 20)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.47.1->-r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.18.0->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.18.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.18.0->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.18.0->-r requirements.txt (line 4)) (2025.6.15)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.47.1->-r requirements.txt (line 20)) (0.16.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==3.47.1->-r requirements.txt (line 20)) (0.46.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.47.1->-r requirements.txt (line 20)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.47.1->-r requirements.txt (line 20)) (1.0.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers->-r requirements.txt (line 19)) (1.5.1)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2->visual-genome->-r requirements.txt (line 26)) (3.9.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 19)) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 27)) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.47.1->-r requirements.txt (line 20)) (0.25.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.47.1->-r requirements.txt (line 20)) (1.3.1)\n",
            "Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2022.10.31-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.48-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.47.1-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading visual_genome-1.1.1-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: iopath, sentence-transformers\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=611bb981d4277b56223e51908b71a53a78e080f411eaa4877ac1d7897e47f406\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=8e3f765d32f6f86d11faf280bf8d2edcabef477341fd72c9cde21cb0eeb9a34d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
            "Successfully built iopath sentence-transformers\n",
            "Installing collected packages: tokenizers, lit, braceexpand, bitsandbytes, websockets, tqdm, regex, pyyaml, psutil, portalocker, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, markupsafe, lightning-utilities, aiofiles, webdataset, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, iopath, huggingface-hub, decord, visual-genome, transformers, matplotlib, gradio-client, gradio, triton, torch, torchvision, torchmetrics, accelerate, torchaudio, timm, sentence-transformers, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.0\n",
            "    Uninstalling huggingface-hub-0.33.0:\n",
            "      Successfully uninstalled huggingface-hub-0.33.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.7.0\n",
            "    Uninstalling accelerate-1.7.0:\n",
            "      Successfully uninstalled accelerate-1.7.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 4.1.0\n",
            "    Uninstalling sentence-transformers-4.1.0:\n",
            "      Successfully uninstalled sentence-transformers-4.1.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.15.2\n",
            "    Uninstalling peft-0.15.2:\n",
            "      Successfully uninstalled peft-0.15.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "diffusers 0.33.1 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.18.0 which is incompatible.\n",
            "dataproc-spark-connect 0.7.5 requires tqdm>=4.67, but you have tqdm 4.64.1 which is incompatible.\n",
            "dataproc-spark-connect 0.7.5 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "bigframes 2.6.0 requires matplotlib>=3.7.1, but you have matplotlib 3.7.0 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.0 which is incompatible.\n",
            "yfinance 0.2.63 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "google-genai 1.20.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-23.2.1 bitsandbytes-0.40.2 braceexpand-0.1.7 decord-0.6.0 gradio-3.47.1 gradio-client-0.6.0 huggingface-hub-0.18.0 iopath-0.1.10 lightning-utilities-0.14.3 lit-18.1.8 markupsafe-2.1.5 matplotlib-3.7.0 numpy-1.26.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.7.0.72 peft-0.4.0 pillow-10.4.0 portalocker-3.2.0 psutil-5.9.4 pyyaml-6.0 regex-2022.10.31 sentence-transformers-2.2.2 timm-0.6.13 tokenizers-0.13.2 torch-2.0.0 torchaudio-2.0.1 torchmetrics-1.7.3 torchvision-0.15.1 tqdm-4.64.1 transformers-4.30.0 triton-2.0.0 visual-genome-1.1.1 webdataset-0.2.48 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "psutil"
                ]
              },
              "id": "0364ec2f92024b5d82a51b76119caef7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb\n",
        "\n",
        "import wandb\n",
        "wandb.login(key=\"639bd4dc2b72f078d0d5e717b50062adbb68fde5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C8tKeXclcdm",
        "outputId": "74e7c8bb-736d-4b5c-e900-4d5884151d19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquangnlse184374\u001b[0m (\u001b[33mquangnlse184374-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ece4ebfb950b4c5399c1be758c440e4a",
            "301986b8a8d3497880a293209ce386a6",
            "8d8ebc448b2d46b99d3d75f148c1dcc6",
            "1384ad1874634e52bf4a0beeac19099a",
            "7eb0de793db84b4eb6750b8aa786a099",
            "f38a888b2de54478894ebf1582650e84",
            "d9cfc4c501ea4cb8906f4ed5db300fcc",
            "3a5f8636eb7d47b9ab7d6f80da660277",
            "fe9ce87467534dc0839f2082ad5b356f",
            "6ba00734c554488a8819048035b6e51f",
            "137989ec65c049ccab6ef1c8f965c94d",
            "ca094f54a4d54679b77ec89b468d910e",
            "d64ae1ad6f154667bb0ea5b7c3610a49",
            "dbdc7cff8135429daedc1c1e2136cda9",
            "2ab11f8a47ee4614a57f98b585c53c4d",
            "5400a3fe115a4cf086d215f31fa884c9",
            "f2885ca831174312a1e0966d6ed7e3ff",
            "24f515d4ba3849bd83f913424df5600c",
            "624ca89c6a36405d96566e8ce28a4234",
            "f0421312aea84425b0cb75fbcc52a9e2",
            "1e4f6fc3885641fd8e09b7b4a9239757",
            "3b568797a76d44078392242ee66a72f6",
            "9374773cdb324fc28f8ff436f7635094",
            "94e4ce8ec09f44d49448cf777f0c70c2",
            "4accd481823248cea883ba78ccdefb12",
            "dda192d88dc2468b917bc39fece7671e",
            "021bcc6516184cc68a666e8c17add9c7",
            "5761d4862c4a417583c998cf1e33aa66",
            "9f2971d42cc545afb49395c78a13fb7c",
            "9240e8a5579440fdb25b01990920ebf3",
            "9f5e0633db1b465597f0fe86e1aaf291",
            "d30aad35b89b456aadd3d4065cc52be8"
          ]
        },
        "id": "-b8T_J55lk_W",
        "outputId": "810fb9a8-f7d5-4e0f-f8a8-aa172f816146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ece4ebfb950b4c5399c1be758c440e4a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/MiniGPT-4/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN_m_pTfmqaV",
        "outputId": "15618d18-7547-454a-ca6f-2df2f5248811"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kh4nh12/ViVQA\n",
        "!cd ViVQA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0G-DkYmtCV",
        "outputId": "29a3d117-66d9-4e15-ee4e-cd0e7da9bafa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ViVQA'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 49 (delta 12), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (49/49), 310.10 KiB | 4.37 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1l1LpLYWlGo0ephvVpTTJiX1JJD2dvWd8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj5S6mL2cvNc",
        "outputId": "19f53cf0-4ced-4e0e-dfd1-fd2466cee928"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l1LpLYWlGo0ephvVpTTJiX1JJD2dvWd8\n",
            "From (redirected): https://drive.google.com/uc?id=1l1LpLYWlGo0ephvVpTTJiX1JJD2dvWd8&confirm=t&uuid=16fa743f-cf91-4d82-b303-9fe892ccbc7f\n",
            "To: /content/MiniGPT-4/data/vivqa_images.zip\n",
            "100% 527M/527M [00:09<00:00, 58.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/MiniGPT-4/data/vivqa_images.zip"
      ],
      "metadata": {
        "id": "3kPD_IbGr11N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir ./ckpt"
      ],
      "metadata": {
        "id": "vSaEnZBd8s9P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-IQN0St9SO_",
        "outputId": "3e7971d2-3c45-402a-8afe-cd43f82bc403"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4/data/ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1HkoUUrjzFGn33cSiUkI-KcT-zysCynAz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIe2B5rk9VhV",
        "outputId": "85b6d1f2-3b10-4a4b-cf83-9901e10d7167"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1HkoUUrjzFGn33cSiUkI-KcT-zysCynAz\n",
            "From (redirected): https://drive.google.com/uc?id=1HkoUUrjzFGn33cSiUkI-KcT-zysCynAz&confirm=t&uuid=821a1779-0d22-4680-83be-6bc08bc53478\n",
            "To: /content/MiniGPT-4/data/ckpt/checkpoint_stage3.pth\n",
            "100% 680M/680M [00:11<00:00, 58.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4mxbOdq9dCY",
        "outputId": "bcf3e7fd-9b63-46b9-d105-e41dd154fcf9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MiniGPT-4/train.py --cfg-path /content/MiniGPT-4/train_configs/minigptv2_finetune_vivqa.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRwA5aNCpJ40",
        "outputId": "9c1d76cb-4254-46fc-deb6-f605a4e91b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-21 10:17:35.571778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750501055.861138    4232 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750501055.933957    4232 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Not using distributed mode\n",
            "2025-06-21 10:17:39,871 [INFO] \n",
            "=====  Running Parameters    =====\n",
            "2025-06-21 10:17:39,871 [INFO] {\n",
            "    \"amp\": true,\n",
            "    \"device\": \"cuda\",\n",
            "    \"dist_url\": \"env://\",\n",
            "    \"distributed\": false,\n",
            "    \"evaluate\": false,\n",
            "    \"init_lr\": 1e-05,\n",
            "    \"iters_per_epoch\": 2000,\n",
            "    \"job_name\": \"minigptv2_finetune\",\n",
            "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
            "    \"max_epoch\": 5,\n",
            "    \"min_lr\": 1e-06,\n",
            "    \"num_workers\": 6,\n",
            "    \"output_dir\": \"vivqa_outputs\",\n",
            "    \"resume_ckpt_path\": null,\n",
            "    \"seed\": 42,\n",
            "    \"task\": \"image_text_pretrain\",\n",
            "    \"train_splits\": [\n",
            "        \"train\"\n",
            "    ],\n",
            "    \"wandb_log\": true,\n",
            "    \"warmup_lr\": 1e-06,\n",
            "    \"warmup_steps\": 500,\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"world_size\": 1\n",
            "}\n",
            "2025-06-21 10:17:39,871 [INFO] \n",
            "======  Dataset Attributes  ======\n",
            "2025-06-21 10:17:39,872 [INFO] \n",
            "======== vivqa =======\n",
            "2025-06-21 10:17:39,872 [INFO] {\n",
            "    \"batch_size\": 2,\n",
            "    \"build_info\": {\n",
            "        \"ann_path\": \"/content/MiniGPT-4/data/ViVQA/train.csv\",\n",
            "        \"image_path\": \"/content/MiniGPT-4/data/images\"\n",
            "    },\n",
            "    \"data_type\": \"images\",\n",
            "    \"sample_ratio\": 100,\n",
            "    \"text_processor\": {\n",
            "        \"train\": {\n",
            "            \"name\": \"blip_caption\"\n",
            "        }\n",
            "    },\n",
            "    \"vis_processor\": {\n",
            "        \"train\": {\n",
            "            \"image_size\": 448,\n",
            "            \"name\": \"blip2_image_train\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "2025-06-21 10:17:39,872 [INFO] \n",
            "======  Model Attributes  ======\n",
            "2025-06-21 10:17:39,872 [INFO] {\n",
            "    \"arch\": \"minigpt_v2\",\n",
            "    \"chat_template\": true,\n",
            "    \"ckpt\": \"./ckpt/checkpoint_stage3.pth\",\n",
            "    \"drop_path_rate\": 0,\n",
            "    \"end_sym\": \"</s>\",\n",
            "    \"freeze_vit\": true,\n",
            "    \"image_size\": 448,\n",
            "    \"llama_model\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
            "    \"lora_alpha\": 16,\n",
            "    \"lora_r\": 64,\n",
            "    \"low_resource\": true,\n",
            "    \"max_txt_len\": 1024,\n",
            "    \"model_type\": \"pretrain\",\n",
            "    \"prompt\": \"\",\n",
            "    \"use_grad_checkpoint\": true,\n",
            "    \"vit_precision\": \"fp16\"\n",
            "}\n",
            "2025-06-21 10:17:39,872 [INFO] Building datasets...\n",
            "2025-06-21 10:17:39,911 [INFO] Loading LLAMA\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 13.0MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.34MB/s]\n",
            "tokenizer_config.json: 100% 1.62k/1.62k [00:00<00:00, 7.78MB/s]\n",
            "config.json: 100% 614/614 [00:00<00:00, 3.90MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 104MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<01:50, 90.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 41.9M/9.98G [00:00<00:53, 185MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 83.9M/9.98G [00:00<00:37, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.98G [00:00<00:32, 304MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.98G [00:00<00:32, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:33, 294MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:00<00:31, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:00<00:31, 313MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.98G [00:01<00:31, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:01<00:36, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:01<00:32, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 409M/9.98G [00:01<00:36, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:01<00:40, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:01<00:35, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 514M/9.98G [00:01<00:37, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 545M/9.98G [00:02<00:35, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:02<00:38, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:02<00:36, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 640M/9.98G [00:02<00:36, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:02<00:38, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 703M/9.98G [00:02<00:38, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 744M/9.98G [00:02<00:33, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.98G [00:03<00:40, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 807M/9.98G [00:03<00:37, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 849M/9.98G [00:03<00:33, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 891M/9.98G [00:03<00:30, 296MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 923M/9.98G [00:03<00:38, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:03<00:35, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.01G/9.98G [00:03<00:31, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.04G/9.98G [00:04<00:39, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.08G/9.98G [00:04<00:35, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:04<00:33, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:05<02:03, 71.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:05<01:39, 88.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.23G/9.98G [00:05<01:14, 118MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.26G/9.98G [00:06<01:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:06<00:54, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.33G/9.98G [00:06<00:43, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:06<00:37, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:06<00:37, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:06<00:37, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:06<00:37, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:06<00:37, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:08<02:11, 64.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.57G/9.98G [00:08<01:33, 90.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:08<01:09, 121MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:08<00:58, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:08<00:50, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.71G/9.98G [00:09<00:56, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:15<08:25, 16.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:15<06:06, 22.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.80G/9.98G [00:15<04:27, 30.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:15<02:58, 45.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.88G/9.98G [00:15<02:16, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:15<01:45, 76.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.94G/9.98G [00:15<01:23, 96.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.97G/9.98G [00:16<01:07, 119MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.00G/9.98G [00:16<00:55, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:16<00:48, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.07G/9.98G [00:16<00:44, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.10G/9.98G [00:16<00:39, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:16<00:35, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:16<00:32, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:16<00:29, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:17<00:31, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:17<00:31, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:17<00:34, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:17<00:34, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.36G/9.98G [00:17<00:32, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:17<00:29, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:17<00:30, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:17<00:32, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:18<00:31, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:18<00:30, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:18<00:29, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:18<00:29, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:18<00:28, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:18<00:28, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:18<00:28, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:18<00:28, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:19<00:27, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:19<00:28, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:19<00:27, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:19<00:32, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.87G/9.98G [00:19<00:34, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:19<00:34, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.94G/9.98G [00:20<00:33, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:20<00:29, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.01G/9.98G [00:20<00:25, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.04G/9.98G [00:25<05:39, 20.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:25<03:46, 30.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:25<03:01, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:25<02:05, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.19G/9.98G [00:26<01:38, 69.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.23G/9.98G [00:26<01:11, 93.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:26<00:55, 122MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:26<00:46, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.34G/9.98G [00:26<00:36, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:26<00:36, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.42G/9.98G [00:26<00:33, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.45G/9.98G [00:27<00:33, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.48G/9.98G [00:27<00:41, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:31<05:06, 21.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.53G/9.98G [00:31<03:37, 29.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:31<02:39, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:32<01:57, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:32<01:20, 78.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:32<01:03, 99.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.70G/9.98G [00:32<00:50, 123MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:32<00:39, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.79G/9.98G [00:32<00:32, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.83G/9.98G [00:32<00:28, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:32<00:29, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.89G/9.98G [00:33<00:28, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.92G/9.98G [00:33<00:31, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.95G/9.98G [00:33<00:43, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.97G/9.98G [00:37<04:58, 20.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:38<03:09, 31.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:38<02:07, 46.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:38<01:39, 59.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.13G/9.98G [00:38<01:10, 82.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.17G/9.98G [00:38<00:52, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:38<00:41, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:38<00:37, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:38<00:33, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:39<00:30, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:39<00:29, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:40<01:27, 63.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:40<01:09, 80.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:40<00:54, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:40<00:45, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:43<03:04, 29.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:44<02:16, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:44<01:41, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:44<01:09, 77.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.63G/9.98G [00:44<00:54, 97.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.68G/9.98G [00:44<00:41, 129MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:44<00:32, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:44<00:33, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:50<04:27, 19.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.82G/9.98G [00:50<02:59, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:50<01:55, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:50<01:30, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:50<01:11, 70.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:50<00:52, 95.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:51<00:39, 124MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:51<00:35, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [00:51<00:30, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.12G/9.98G [00:51<00:27, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:51<00:25, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.18G/9.98G [00:51<00:22, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.21G/9.98G [00:51<00:21, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:51<00:21, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.98G [00:52<00:19, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.98G [00:52<00:20, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:52<00:18, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.37G/9.98G [00:52<00:17, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:52<00:18, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.44G/9.98G [00:52<00:22, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:52<00:21, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.51G/9.98G [00:53<00:20, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:53<00:24, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:53<00:22, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.61G/9.98G [00:53<00:19, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.64G/9.98G [01:00<04:31, 16.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.66G/9.98G [01:00<03:44, 19.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [01:00<02:23, 29.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [01:00<01:36, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.98G [01:00<01:14, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.82G/9.98G [01:01<00:53, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.85G/9.98G [01:01<00:42, 97.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [01:01<00:31, 128MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [01:01<00:27, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [01:01<00:24, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [01:01<00:21, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [01:01<00:21, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.98G [01:01<00:17, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.98G [01:02<00:16, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.12G/9.98G [01:02<00:16, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [01:02<00:16, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.19G/9.98G [01:02<00:15, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.23G/9.98G [01:02<00:15, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.26G/9.98G [01:02<00:15, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.30G/9.98G [01:02<00:13, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.33G/9.98G [01:03<00:15, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [01:03<00:15, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.98G [01:03<00:13, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [01:03<00:12, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [01:03<00:14, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.51G/9.98G [01:03<00:14, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [01:03<00:12, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [01:04<00:12, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [01:04<00:14, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.67G/9.98G [01:04<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.70G/9.98G [01:04<00:15, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.73G/9.98G [01:04<00:14, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.76G/9.98G [01:04<00:13, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [01:04<00:13, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.83G/9.98G [01:05<00:13, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.86G/9.98G [01:05<00:12, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.89G/9.98G [01:05<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [01:05<00:11, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [01:05<00:11, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [01:05<00:11, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [01:05<00:11, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [01:05<00:10, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [01:06<00:10, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [01:06<00:09, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [01:06<00:09, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [01:06<00:08, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.27G/9.98G [01:06<00:08, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [01:06<00:13, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [01:15<03:04, 14.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.36G/9.98G [01:16<02:55, 14.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [01:18<03:18, 13.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.42G/9.98G [01:18<02:04, 20.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.46G/9.98G [01:19<01:29, 28.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.49G/9.98G [01:19<01:05, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [01:19<00:49, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.55G/9.98G [01:19<00:37, 64.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [01:19<00:28, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.61G/9.98G [01:19<00:21, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.64G/9.98G [01:19<00:17, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [01:19<00:15, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.71G/9.98G [01:20<00:13, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.74G/9.98G [01:20<00:11, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.77G/9.98G [01:20<00:10, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.80G/9.98G [01:20<00:09, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [01:20<00:09, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.86G/9.98G [01:20<00:09, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [01:20<00:08, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.93G/9.98G [01:21<00:11, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.97G/9.98G [01:21<00:09, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [01:21<00:08, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [01:21<00:07, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.08G/9.98G [01:21<00:07, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.13G/9.98G [01:21<00:06, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [01:21<00:05, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [01:22<00:07, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [01:22<00:06, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [01:22<00:05, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.34G/9.98G [01:22<00:06, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.37G/9.98G [01:22<00:06, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [01:22<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [01:22<00:05, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.48G/9.98G [01:23<00:06, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [01:23<00:06, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.98G [01:23<00:05, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [01:23<00:04, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [01:23<00:04, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.68G/9.98G [01:23<00:05, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [01:24<00:05, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [01:24<00:04, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.80G/9.98G [01:24<00:04, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [01:24<00:05, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [01:24<00:05, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [01:24<00:05, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [01:25<00:05, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [01:25<00:06, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.00G/9.98G [01:25<00:04, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [01:25<00:04, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [01:25<00:03, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [01:25<00:03, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [01:29<00:26, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [01:29<00:19, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [01:29<00:14, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [01:29<00:09, 78.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.27G/9.98G [01:29<00:07, 93.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.30G/9.98G [01:29<00:06, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.33G/9.98G [01:29<00:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [01:30<00:03, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.40G/9.98G [01:30<00:03, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.44G/9.98G [01:30<00:02, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.47G/9.98G [01:30<00:02, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.50G/9.98G [01:30<00:02, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.53G/9.98G [01:30<00:01, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.56G/9.98G [01:30<00:01, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.59G/9.98G [01:31<00:02, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [01:37<00:25, 14.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [01:37<00:16, 20.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [01:37<00:10, 28.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.72G/9.98G [01:37<00:05, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [01:37<00:03, 62.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [01:38<00:02, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [01:38<00:01, 115MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [01:38<00:00, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [01:38<00:00, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [01:39<00:00, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:42<00:00, 97.3MB/s]\n",
            "Downloading shards:  50% 1/2 [01:42<01:42, 102.67s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:22, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 41.9M/3.50G [00:00<00:19, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 73.4M/3.50G [00:00<00:15, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 105M/3.50G [00:00<00:21, 161MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:15, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 189M/3.50G [00:00<00:12, 269MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 220M/3.50G [00:00<00:11, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 252M/3.50G [00:01<00:12, 260MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 294M/3.50G [00:01<00:11, 271MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:10, 296MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 377M/3.50G [00:01<00:10, 311MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 419M/3.50G [00:01<00:11, 271MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:01<00:12, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:01<00:11, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:02<00:11, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 556M/3.50G [00:02<00:11, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 587M/3.50G [00:02<00:10, 267MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:02<00:12, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 650M/3.50G [00:02<00:11, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 692M/3.50G [00:02<00:10, 271MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 724M/3.50G [00:02<00:11, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:10, 265MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 807M/3.50G [00:03<00:09, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 839M/3.50G [00:03<00:12, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 870M/3.50G [00:03<00:10, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:03<00:09, 276MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:03<00:10, 255MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 975M/3.50G [00:03<00:10, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:04<00:10, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:04<00:09, 263MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.09G/3.50G [00:04<00:08, 285MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.12G/3.50G [00:04<00:09, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:04<00:10, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.18G/3.50G [00:04<00:10, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:05<00:13, 172MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.26G/3.50G [00:05<00:10, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.30G/3.50G [00:05<00:09, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.34G/3.50G [00:05<00:08, 262MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.38G/3.50G [00:05<00:07, 289MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:05<00:07, 294MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.45G/3.50G [00:05<00:07, 290MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:05<00:06, 295MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:05<00:07, 274MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:06<00:07, 269MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:06<00:07, 260MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:06<00:07, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:06<00:07, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:06<00:07, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:06<00:07, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:06<00:07, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:07<00:07, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:07<00:07, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:07<00:09, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:12<01:43, 16.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:13<01:11, 22.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:13<00:49, 32.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:13<00:35, 44.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:13<00:23, 65.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.01G/3.50G [00:13<00:17, 83.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:13<00:14, 104MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:13<00:11, 124MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:13<00:09, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:14<00:08, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:14<00:07, 172MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:14<00:08, 151MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:19<01:11, 17.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:19<00:43, 28.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:19<00:28, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:19<00:21, 54.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.38G/3.50G [00:19<00:14, 76.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:25<01:01, 17.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:25<00:39, 26.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:25<00:26, 37.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.54G/3.50G [00:25<00:18, 52.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.57G/3.50G [00:25<00:13, 66.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.60G/3.50G [00:25<00:10, 84.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.63G/3.50G [00:25<00:08, 105MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:26<00:06, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.72G/3.50G [00:26<00:04, 164MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:26<00:04, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.78G/3.50G [00:26<00:03, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:26<00:03, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:26<00:02, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.87G/3.50G [00:26<00:02, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:26<00:02, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:27<00:02, 253MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:27<00:02, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:27<00:02, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:27<00:02, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.07G/3.50G [00:27<00:01, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:27<00:01, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:27<00:01, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:28<00:01, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.22G/3.50G [00:28<00:01, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.26G/3.50G [00:28<00:00, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.29G/3.50G [00:28<00:00, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:28<00:00, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:28<00:00, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:28<00:00, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:29<00:00, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:29<00:00, 119MB/s]\n",
            "Downloading shards: 100% 2/2 [02:12<00:00, 66.13s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:05<00:00, 32.85s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.37MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n",
            "2025-06-21 10:21:10,281 [INFO] Loading LLAMA Done\n",
            "2025-06-21 10:21:10,281 [INFO] Loading VIT\n",
            "2025-06-21 10:21:26,970 [INFO] Downloading: \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/eva_vit_g.pth\" to /root/.cache/torch/hub/checkpoints/eva_vit_g.pth\n",
            "\n",
            "100% 1.89G/1.89G [00:50<00:00, 40.0MB/s]\n",
            "Position interpolate from 16x16 to 32x32\n",
            "2025-06-21 10:22:22,118 [INFO] freeze vision encoder\n",
            "2025-06-21 10:22:22,118 [INFO] Loading VIT Done\n",
            "Load Minigpt-4-LLM Checkpoint: ./ckpt/checkpoint_stage3.pth\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquangnlse184374\u001b[0m (\u001b[33mquangnlse184374-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MiniGPT-4/data/wandb/run-20250621_102225-n56l9r1r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mminigptv2_finetune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/quangnlse184374-fpt-university/minigptv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/quangnlse184374-fpt-university/minigptv/runs/n56l9r1r\u001b[0m\n",
            "2025-06-21 10:22:27,582 [INFO] Start training\n",
            "2025-06-21 10:22:28,105 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
            "2025-06-21 10:22:28,105 [INFO] Loaded 11999 records for train split from the dataset.\n",
            "batch sizes [[2]]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
            "llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
            "llama_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
            "llama_proj.weight\n",
            "llama_proj.bias\n",
            "2025-06-21 10:22:28,145 [INFO] number of trainable parameters: 56627200\n",
            "2025-06-21 10:22:28,146 [INFO] Start training epoch 0, 2000 iters per inner epoch.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Train: data epoch: [0]  [   0/2000]  eta: 6:33:54  lr: 0.000001  loss: 7.8438  time: 11.8170  data: 0.0000  max mem: 10495\n",
            "Train: data epoch: [0]  [  50/2000]  eta: 2:54:44  lr: 0.000002  loss: 5.9675  time: 5.3553  data: 0.0000  max mem: 11058\n",
            "Train: data epoch: [0]  [ 100/2000]  eta: 2:49:06  lr: 0.000003  loss: 6.4708  time: 5.2648  data: 0.0000  max mem: 11058\n",
            "Train: data epoch: [0]  [ 150/2000]  eta: 2:44:10  lr: 0.000004  loss: 5.7925  time: 5.2777  data: 0.0000  max mem: 11058\n",
            "Train: data epoch: [0]  [ 200/2000]  eta: 2:39:22  lr: 0.000005  loss: 4.3553  time: 5.2958  data: 0.0000  max mem: 11058\n",
            "Train: data epoch: [0]  [ 250/2000]  eta: 2:34:24  lr: 0.000005  loss: 4.7092  time: 5.2696  data: 0.0000  max mem: 11058\n",
            "Train: data epoch: [0]  [ 300/2000]  eta: 2:29:45  lr: 0.000006  loss: 2.5387  time: 5.1983  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 350/2000]  eta: 2:25:33  lr: 0.000007  loss: 1.7226  time: 5.3428  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 400/2000]  eta: 2:21:18  lr: 0.000008  loss: 1.5024  time: 5.3517  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 450/2000]  eta: 2:16:49  lr: 0.000009  loss: 1.5936  time: 5.3208  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 500/2000]  eta: 2:12:15  lr: 0.000010  loss: 0.6732  time: 5.2939  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 550/2000]  eta: 2:07:46  lr: 0.000010  loss: 1.3900  time: 5.2623  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 600/2000]  eta: 2:03:22  lr: 0.000010  loss: 1.1590  time: 5.2258  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 650/2000]  eta: 1:58:54  lr: 0.000010  loss: 3.3863  time: 5.2900  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 700/2000]  eta: 1:54:33  lr: 0.000010  loss: 0.9282  time: 5.4069  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 750/2000]  eta: 1:50:03  lr: 0.000010  loss: 0.6389  time: 5.2077  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 800/2000]  eta: 1:45:37  lr: 0.000010  loss: 0.8901  time: 5.1806  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 850/2000]  eta: 1:41:11  lr: 0.000010  loss: 0.8223  time: 5.2560  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 900/2000]  eta: 1:36:47  lr: 0.000010  loss: 1.2239  time: 5.2805  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [ 950/2000]  eta: 1:32:22  lr: 0.000010  loss: 0.5848  time: 5.3301  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1000/2000]  eta: 1:27:59  lr: 0.000010  loss: 0.2451  time: 5.2373  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1050/2000]  eta: 1:23:36  lr: 0.000010  loss: 0.6154  time: 5.2844  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1100/2000]  eta: 1:19:12  lr: 0.000010  loss: 1.2175  time: 5.2700  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1150/2000]  eta: 1:14:46  lr: 0.000010  loss: 0.7036  time: 5.2715  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1200/2000]  eta: 1:10:22  lr: 0.000010  loss: 0.3416  time: 5.3331  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1250/2000]  eta: 1:06:00  lr: 0.000010  loss: 0.9392  time: 5.3493  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1300/2000]  eta: 1:01:35  lr: 0.000010  loss: 0.7119  time: 5.2388  data: 0.0000  max mem: 11061\n",
            "Train: data epoch: [0]  [1350/2000]  eta: 0:57:12  lr: 0.000010  loss: 1.1048  time: 5.3446  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1400/2000]  eta: 0:52:47  lr: 0.000010  loss: 1.1931  time: 5.3132  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1450/2000]  eta: 0:48:23  lr: 0.000010  loss: 0.3825  time: 5.1958  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1500/2000]  eta: 0:44:00  lr: 0.000010  loss: 1.2864  time: 5.3259  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1550/2000]  eta: 0:39:36  lr: 0.000009  loss: 0.5183  time: 5.3638  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1600/2000]  eta: 0:35:12  lr: 0.000009  loss: 0.9824  time: 5.3675  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1650/2000]  eta: 0:30:48  lr: 0.000009  loss: 0.3578  time: 5.2887  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1700/2000]  eta: 0:26:24  lr: 0.000009  loss: 1.6649  time: 5.2798  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1750/2000]  eta: 0:22:00  lr: 0.000009  loss: 2.2639  time: 5.2150  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1800/2000]  eta: 0:17:36  lr: 0.000009  loss: 0.3806  time: 5.3190  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1850/2000]  eta: 0:13:12  lr: 0.000009  loss: 1.0255  time: 5.2390  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1900/2000]  eta: 0:08:48  lr: 0.000009  loss: 0.1827  time: 5.2305  data: 0.0000  max mem: 11066\n",
            "Train: data epoch: [0]  [1950/2000]  eta: 0:04:24  lr: 0.000009  loss: 0.8501  time: 5.2894  data: 0.0000  max mem: 11066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_xQ6EAkui8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}